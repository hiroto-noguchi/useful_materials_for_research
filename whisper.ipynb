{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOpEKxoOkl2C1ixyuwvVSX6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hiroto-noguchi/useful_materials_for_research/blob/main/whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用手順（※Safariではメモリーエラーで動作しない場合があります。他のブラウザの使用を推奨します。）\n",
        "\n",
        "1.   ランタイムのタイプをGPU（T4 GPUなど）に変更する。\n",
        "2.   すべてのセルを実行する\n",
        "3.   ダイアログから書き起こしたい音声ファイルをアップロードする。（スクリプトを書き換えられるなら、ドライブをマウントするほうが実行速度は速いです。）\n",
        "\n",
        "※詳しい説明は、ご本家のGitHubページで確認できます。 https://github.com/openai/whisper"
      ],
      "metadata": {
        "id": "sEHR0AMyy5KI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yv3M7GF4o-H_"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "ｍodel = whisper.load_model(\"large\")"
      ],
      "metadata": {
        "id": "DkhIaq9apo8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/"
      ],
      "metadata": {
        "id": "ZKICukSTrZRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pickle\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for file in uploaded.keys():\n",
        "  result = model.transcribe(file, verbose=True)\n",
        "  #result = model.transcribe(file, verbose=True, language='en')\n",
        "  #result = model.transcribe(file, verbose=True, language='ja')\n",
        "  text = result['text']\n",
        "\n",
        "  with open(file + \".txt\", \"w\") as text_file:\n",
        "    text_file.write(text)\n",
        "\n",
        "    files.download(file + \".txt\")\n",
        "\n",
        "'''\n",
        "  with open(file + \".pickle\", mode=\"wb\") as pickle_file:\n",
        "    pickle.dump(result, pickle_file)\n",
        "    files.download(file + \".pickle\")\n",
        "'''"
      ],
      "metadata": {
        "id": "MTKYdOauvAUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "with open(file + \".pickle\", mode=\"rb\") as pickle_file_read:\n",
        "      file_read = pickle.load(pickle_file_read)\n",
        "'''"
      ],
      "metadata": {
        "id": "_yjEjYGGu9yY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
