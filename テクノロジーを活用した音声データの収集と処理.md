# テクノロジーを活用した音声データの収集と処理
## データ収集
言語/ライブラリ: JavaScript/jsPsych <br>
環境: Cognition.

### 産出実験（オンラインでの録音データ-->文字列化された音声）
```js
var jsPsych = initJsPsych({
    use_webaudio: false,
    show_progress_bar: true,
    on_finish: function() {
      jsPsych.data.displayData()
      //[jsPsych.data.displayData(),
      //jsPsych.data.get().localSave('csv','mydata.csv')];
    }
});

/* ここでは、以下の2つの画像ファイルがアップロードされていることを前提としている。
picture_test_1.png
picture_test_2.png
アップロードした画像のファイル名に応じて変更する。追加する場合はコンマでつなぐ。*/
var img_list = ['picture_test_1.png',
'picture_test_2.png'
];

var preload = {
    type: jsPsychPreload,
    images: img_list,
};

// 必要に応じて項目を追加する。
var info = {
  type: jsPsychSurveyText,
  questions: [
    {prompt: '名前'},
    {prompt: '言語歴', rows: 3},
  ]
};

var initialize_mic = {
    type: jsPsychInitializeMicrophone,
    device_select_message: 'マイクを選択',
    button_label: "つぎへ",
};

/*提示するものをHTMLで記述する。ここでは、文と画像を表示するようにしている。
さきほどアップロードしたファイルに合わせてファイル名を変更する。*/
var item_list = [
    {stimulus: '<h1>画像に関連するテーマで音声を吹き込んでください。</h1><br><img src="picture_test_1.png"  width="300">'},
    {stimulus: '<h1>画像に関連するテーマで音声を吹き込んでください。</h1><br><img src="picture_test_2.png"  width="300">'},
];

// 提示順はランダマイズされている。
var randomized_item_list = jsPsych.randomization.shuffle(item_list)

var record = {
    type: jsPsychHtmlAudioResponse,
    stimulus: jsPsych.timelineVariable('stimulus'),
    recording_duration: 10000,
    allow_playback: true,
    done_button_label: '録音終了',
    accept_button_label: 'つぎへ',
    record_again_button_label: '再録音'  
};

// ランダマイズしない場合はtimeline_variablesの値をitem_listに書き換える。
var record_timeline = {
  timeline: [record],
  timeline_variables: randomized_item_list,
    // timeline_variables: item_list,
};

var goodbye = {
    type: jsPsychHtmlButtonResponse,
    stimulus: '<p>ご回答ありがとうございました。</p>',
    choices: ['データ送信'],
    response_ends_trial: true,
};

var timeline = [
  preload,
  info,
  initialize_mic, 
  record_timeline,
  goodbye
];
jsPsych.run(timeline);
```
### 知覚実験 (おまけ)
## 前処理
言語: Python <br>
環境: Google Colaboratory (or Jupyter Notebookなど)
### Base64 to Wav
```py
import pandas as pd
import base64
from pydub import AudioSegment
import os

# 保存先のパスを指定する。ファイルをローカルに保存するパス
file_path = './audio_files'

# 保存先ディレクトリが存在しない場合は作成する
if not os.path.exists(file_path):
    os.makedirs(file_path)

# Base64 でエンコードされたオーディオファイルに変換する関数を定義する。
def convert_snd(s):
    # Base64 デコード
    snd = base64.b64decode(s)
    return snd

# CSV ファイルを読み込む。
df = pd.read_csv('response.csv')  # ローカル環境でのCSVファイルパスを指定

# 各行について処理を実行する。
for data in df.itertuples():
    # trial_type 列の値が 'html-audio-response' なら、
    if data.trial_type == 'html-audio-response':
        # ファイル名を生成し、
        file_base = str(data.run_id) + str(data.trial_index)
        # オーディオファイルを変換する。
        snd = convert_snd(data.response)
        # webmファイルとして保存
        temp_webm_path = os.path.join(file_path, file_base + '.webm')
        with open(temp_webm_path, 'wb') as f:
            f.write(snd)
        # webmをwavに変換
        audio = AudioSegment.from_file(temp_webm_path, format="webm")
        wav_path = os.path.join(file_path, file_base + '.wav')
        audio.export(wav_path, format="wav")
```
### 16kHzへのリサンプリング
```
import os
import librosa
import soundfile as sf

def resample_folder_with_librosa(input_folder, output_folder):
    for filename in os.listdir(input_folder):
        if filename.endswith(".wav"):
            input_path = os.path.join(input_folder, filename)
            y, sr = librosa.load(input_path, sr=None)
            y_resampled = librosa.resample(y, orig_sr=sr, target_sr=16000)
            base, ext = os.path.splitext(filename)
            output_filename = f"{base}_16000{ext}"
            output_path = os.path.join(output_folder, output_filename)
            os.makedirs(output_folder, exist_ok=True)
            sf.write(output_path, y_resampled, 16000)

# 音声ファイルのあるフォルダーのパスに変更する。
input_folder = "/content/drive/MyDrive"

# 音声ファイルを出力するフォルダーのパスに変更する。
output_folder = "/content/drive/MyDrive"
resample_folder_with_librosa(input_folder, output_folder)
```
## 書き起こし(と時刻情報を利用した切り出し, かな文字化)
言語/ライブラリ: Python/Whisper <br>
環境: Google Colaboratory (GPU利用)
### MFAでアノテーションしたい場合
### Juliusでアノテーションしたい場合
## アノテーション(Forced Alignment)
言語/ライブラリ: Python/Montreal Forced Aligner (MFA, 多言語対応), PySegmentKit (Perl/Julius のラッパー, 日本語向け) <br>
環境: Google Colaboratory or Jupyter Notebookなど (MFAは仮想環境でcondaによるインストールを推奨)
### Montreal Forced Aligner
### PySegmentKit (Julius のラッパー)
## 計測
言語/ライブラリ: Python/Parselmouth (Praatのラッパー), TextGridTools <br>
環境: Google Colaboratory (or Jupyter Notebookなど)
### Parselmouth
### TextGridTools
## データフレームと可視化
言語/ライブラリ: Python/Pandas, Matplotlib <br>
環境: Google Colaboratory (or Jupyter Notebookなど)
### データフレーム
### 可視化
